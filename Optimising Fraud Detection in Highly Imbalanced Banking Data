import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    roc_auc_score,
    classification_report,
    confusion_matrix,
    roc_curve
)
from sklearn.utils import resample

# 1. Load Data
# CHANGE this to your actual file name
df = pd.read_csv("Bank Account Fraud Dataset.csv")

# 2. Exploratory Data Analysis
print("Dataset Info:")
print(df.info())

# Target distribution
sns.countplot(x='fraud_bool', data=df)
plt.title("Fraud vs Non-Fraud")
plt.show()

# Visualize specific numeric features vs Fraud
num_cols = ['income', 'customer_age', 'credit_risk_score', 'zip_count_4w', 'velocity_6h']
for col in num_cols:
    plt.figure(figsize=(5,3))
    sns.boxplot(x='fraud_bool', y=col, data=df)
    plt.title(f"{col} vs Fraud")
    plt.show()

# 3. Preprocessing
# Drop high cardinality column
df = df.drop(columns=['source'])  

# Encode categorical columns
cat_cols = df.select_dtypes(include='object').columns
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col].astype(str))

# Fill missing values with median
df.fillna(df.median(numeric_only=True), inplace=True)

# 4. Train/Test Split
X = df.drop(columns='fraud_bool')
y = df['fraud_bool']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 5. Model Training (Using RandomForest instead of LightGBM)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 6. Prediction and Evaluation
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:,1]

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nROC AUC Score:")
print(roc_auc_score(y_test, y_prob))

# 7. Feature Importance
feat_imp = pd.Series(model.feature_importances_, index=X.columns).sort_values()
feat_imp.tail(10).plot(kind='barh', title='Top 10 Important Features', figsize=(6,4))
plt.show()
